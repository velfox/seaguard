<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, shrink-to-fit=no, user-scalable=no"
    />
    <title>Mui Detection Stream</title>
  </head>
  <body>
    <script src="https://cdn.jsdelivr.net/npm/@cloud-annotations/models@0.1.1"></script>
    <script src="https://cdn.jsdelivr.net/npm/hls.js@0.12.4"></script>
    <video
      id="video"
      width="1280"
      height="720"
      style="position: fixed;"
      muted
      controls
    ></video>
    <canvas
      id="canvas"
      width="1280"
      height="720"
      style="position: fixed;"
    ></canvas>
    <script>
      // Test stream from: https://bitmovin.com/mpeg-dash-hls-examples-sample-streams/
      const LIVE_STREAM_URL = "vid3/strand.m3u8";

      const video = document.getElementById("video");
      const canvas = document.getElementById("canvas");

      video.addEventListener("loadeddata", function () {
        // Model from: https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd
        models.load("/model_web").then((model) => detectFrame(model));
      });

      const detectFrame = async (model) => {
        const predictions = await model.detect(video);
        renderPredictions(predictions);
        requestAnimationFrame(() => {
          detectFrame(model);
        });
      };

      const renderPredictions = (predictions) => {
        const ctx = canvas.getContext("2d");
        ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);
        // Font options.
        const font = "16px sans-serif";
        ctx.font = font;
        ctx.textBaseline = "top";
        predictions.forEach((prediction) => {
          const x = prediction.bbox[0];
          const y = prediction.bbox[1];
          const width = prediction.bbox[2];
          const height = prediction.bbox[3];
          const label = `${prediction.class}: ${prediction.score.toFixed(2)}`;
          // Draw the bounding box.
          ctx.strokeStyle = "#FFFF3F";
          ctx.lineWidth = 5;
          ctx.strokeRect(x, y, width, height);
          // Draw the label background.
          ctx.fillStyle = "#FFFF3F";
          const textWidth = ctx.measureText(label).width;
          const textHeight = parseInt(font, 10); // base 10
          ctx.fillRect(x, y, textWidth + 4, textHeight + 4);
        });

        predictions.forEach((prediction) => {
          const x = prediction.bbox[0];
          const y = prediction.bbox[1];
          const label = `${prediction.class}: ${prediction.score.toFixed(2)}`;
          // Draw the text last to ensure it's on top.
          ctx.fillStyle = "#000000";
          ctx.fillText(label, x, y);
        });
      };

      if (Hls.isSupported()) {
        const config = { liveDurationInfinity: true };
        const hls = new Hls(config);
        hls.loadSource(LIVE_STREAM_URL);
        hls.attachMedia(video);
        hls.on(Hls.Events.MANIFEST_PARSED, function () {
          video.play();
        });
      }


      

      // hls.js is not supported on platforms that do not have Media Source Extensions (MSE) enabled.
      // When the browser has built-in HLS support (check using `canPlayType`), we can provide an HLS manifest (i.e. .m3u8 URL) directly to the video element throught the `src` property.
      // This is using the built-in support of the plain video element, without using hls.js.
      // Note: it would be more normal to wait on the 'canplay' event below however on Safari (where you are most likely to find built-in HLS support) the video.src URL must be on the user-driven
      // white-list before a 'canplay' event will be emitted; the last video event that can be reliably listened-for when the URL is not on the white-list is 'loadedmetadata'.
      else if (video.canPlayType("application/vnd.apple.mpegurl")) {
        video.src = LIVE_STREAM_URL;
        video.addEventListener("loadedmetadata", function () {
          video.play();
        });
      }
    </script>
  </body>
</html>
